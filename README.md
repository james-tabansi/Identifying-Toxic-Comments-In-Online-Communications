# Identifying-Toxic-Comments-In-Online-Communications

## **Problem Statement:**

Online platforms often face the challenge of identifying and managing toxic comments, which can include abusive language, hate speech, or threats. This project aims to develop a classification system capable of identifying toxic comments in online communications using various vector representations of text data. Specifically, the project explores the performance of both traditional machine learning models and sequential neural networks in classifying toxic comments.

## **Key Components:**

1. **Text Vectorization Techniques:**
   The project investigates multiple text vectorization techniques, such as Bag-of-Words (BoW), TF-IDF (Term Frequency-Inverse Document Frequency), word embeddings (e.g., Word2Vec, GloVe).

2. **Modeling:**
   We implemented the following models
   **Traditional Machine Learning Models:** specifically Decision Tree, and Gradient Boosting classifier to build classification models using the vectorized text representations.
   **Sequential Neural Networks:**
   Implemented sequential neural network architectures, such as Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, to capture sequential dependencies in the text data and classify toxic comments.

6. **Evaluation Metrics:**
   The Recall and Accuracy scores were used to assess the performance of the classification models. 

**Expected Outcome:**

By exploring the performance of various vector representations and classification models, the project aims to identify the most effective approach for accurately detecting toxic comments in online communications. The insights gained from this project could inform the development of automated moderation systems for online platforms, facilitating a safer and more respectful online environment for users.

